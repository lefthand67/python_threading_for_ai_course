{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ff3857-ea0a-464e-b055-eb2b016e2e65",
   "metadata": {},
   "source": [
    "# PHASE 1. FOUNDATIONS: CONCURRENCY, THE GIL, AND THREADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8856b966-7df7-4f4b-82ea-9fd79477d50d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:17:50.344810Z",
     "iopub.status.busy": "2025-11-03T11:17:50.344247Z",
     "iopub.status.idle": "2025-11-03T11:17:50.373788Z",
     "shell.execute_reply": "2025-11-03T11:17:50.369340Z",
     "shell.execute_reply.started": "2025-11-03T11:17:50.344736Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.14.0 free-threading build (main, Nov  1 2025, 00:37:47) [GCC 14.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e495f-0a0c-4986-a1ce-20fab4cefe73",
   "metadata": {},
   "source": [
    "# <b>1.1 Comparing Sequential vs Concurrent</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f43a4b-990b-4055-a37b-f1874d32d8e1",
   "metadata": {},
   "source": [
    "## pthreads - C example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b47b6-7e8a-447d-a154-36850d85e177",
   "metadata": {},
   "source": [
    "### `sleep` example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce87d9-7cb0-419f-877a-d66e4bf00a47",
   "metadata": {},
   "source": [
    "Let's write a C program that creates two threads. One will print a series of letters, and the other will print a series of numbers. Because of concurrent execution, the output will be interleaved in a non-deterministic way, demonstrating the core concept.\n",
    "\n",
    "**To Compile and Run:**\n",
    "\n",
    "You must link the `pthread` library when compiling.\n",
    "\n",
    "```bash\n",
    "gcc -o concurrent concurrent.c -lpthread\n",
    "./concurrent\n",
    "```\n",
    "\n",
    "When you run this, you will *not* see all letters then all numbers, or vice versa. You will see a mixed output like this:\n",
    "\n",
    "```\n",
    "Main: Starting threads...\n",
    "Main: Threads started. Waiting for them to finish...\n",
    "Number: 0\n",
    "Letter: A\n",
    "Number: 1\n",
    "Letter: B\n",
    "...\n",
    "```\n",
    "\n",
    "The exact order will change each time you run it. This is the non-deterministic scheduling of the operating system in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fdf4e7-5619-4fe7-96bd-fdca6cfa330b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T19:08:33.199240Z",
     "iopub.status.busy": "2025-11-02T19:08:33.198788Z",
     "iopub.status.idle": "2025-11-02T19:08:38.310511Z",
     "shell.execute_reply": "2025-11-02T19:08:38.309630Z",
     "shell.execute_reply.started": "2025-11-02T19:08:33.199202Z"
    },
    "tags": []
   },
   "source": [
    "```c\n",
    "#include <pthread.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <unistd.h> // for sleep()\n",
    "\n",
    "// A simple function that will be run in a thread.\n",
    "// It takes a void* argument and returns a void*.\n",
    "// This is the required signature for a thread function.\n",
    "void* print_numbers(void* arg);\n",
    "void* print_letters(void* arg);\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    pthread_t thread1, thread2; // These are handles for our threads, like file descriptors.\n",
    "\n",
    "    printf(\"Main: Starting threads...\\n\");\n",
    "\n",
    "    // Create the first thread. It will run the print_numbers function.\n",
    "    if (pthread_create(&thread1, NULL, print_numbers, NULL) != 0) {\n",
    "        perror(\"Failed to create thread1\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Create the second thread. It will run the print_letters function.\n",
    "    if (pthread_create(&thread2, NULL, print_letters, NULL) != 0) {\n",
    "        perror(\"Failed to create thread2\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    printf(\"Main: Threads started. Waiting for them to finish...\\n\");\n",
    "\n",
    "    // pthread_join is crucial. It makes the main thread WAIT for the other threads to finish.\n",
    "    // If we didn't do this, main might exit immediately, killing the child threads.\n",
    "    pthread_join(thread1, NULL);\n",
    "    pthread_join(thread2, NULL);\n",
    "\n",
    "    printf(\"Main: Both threads have finished.\\n\");\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void* print_numbers(void* arg)\n",
    "{\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        printf(\"Number: %d\\n\", i);\n",
    "        sleep(1); // 1 sec\n",
    "    }\n",
    "    return NULL;\n",
    "}\n",
    "void* print_letters(void* arg)\n",
    "{\n",
    "    for (char c = 'a'; c <= 'e'; c++) {\n",
    "        printf(\"Letter: %c\\n\", c);\n",
    "        sleep(1);\n",
    "    }\n",
    "    return NULL;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20094845-f4a6-4fef-a0d5-a9e09cd4a3c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:18:13.257357Z",
     "iopub.status.busy": "2025-11-03T11:18:13.253088Z",
     "iopub.status.idle": "2025-11-03T11:18:18.620307Z",
     "shell.execute_reply": "2025-11-03T11:18:18.618112Z",
     "shell.execute_reply.started": "2025-11-03T11:18:13.257234Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Starting threads...\n",
      "Number: 0\n",
      "Main: Threads started. Waiting for them to finish...\n",
      "Letter: a\n",
      "Number: 1\n",
      "Letter: b\n",
      "Letter: c\n",
      "Number: 2\n",
      "Number: 3\n",
      "Letter: d\n",
      "Number: 4\n",
      "Letter: e\n",
      "Main: Both threads have finished.\n"
     ]
    }
   ],
   "source": [
    "!gcc -o src/concurrent_c src/concurrent.c -lpthread\n",
    "!src/concurrent_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0352a44-5782-42f3-bb6e-ca2ccf809678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:18:27.187758Z",
     "iopub.status.busy": "2025-11-03T11:18:27.187132Z",
     "iopub.status.idle": "2025-11-03T11:18:32.322246Z",
     "shell.execute_reply": "2025-11-03T11:18:32.321387Z",
     "shell.execute_reply.started": "2025-11-03T11:18:27.187696Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Starting threads...\n",
      "Main: Threads started. Waiting for them to finish...\n",
      "Number: 0\n",
      "Letter: a\n",
      "Number: 1\n",
      "Letter: b\n",
      "Number: 2\n",
      "Letter: c\n",
      "Number: 3\n",
      "Letter: d\n",
      "Number: 4\n",
      "Letter: e\n",
      "Main: Both threads have finished.\n"
     ]
    }
   ],
   "source": [
    "!src/concurrent_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd648a06-a36b-4bc9-b4a9-cdc3f65e5bc5",
   "metadata": {},
   "source": [
    "**Key Concepts Illustrated:**\n",
    "\n",
    "1.  `pthread_t`: A type for a thread \"handle\". It's how we reference the thread.\n",
    "2.  **`pthread_create`**: The system call to create a new thread. It takes:\n",
    "    *   A pointer to a `pthread_t` to store the handle.\n",
    "    *   Thread attributes (we use `NULL` for defaults).\n",
    "    *   The *function pointer* to the routine the thread will execute.\n",
    "    *   A *single argument* to pass to that function (we use `NULL` for now).\n",
    "3.  **Thread Function**: Must be of the form `void* function_name(void* arg)`. This is the independent path of execution.\n",
    "4.  `pthread_join`: This is how one thread waits for another to terminate. The `main` function blocks here until `thread1` and `thread2` are done. This is vital for coordination, see an example with the commented out join commands below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194118bb-53d1-4109-afc4-b8d4bc8fb985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T19:11:44.575839Z",
     "iopub.status.busy": "2025-11-02T19:11:44.574756Z",
     "iopub.status.idle": "2025-11-02T19:11:44.716949Z",
     "shell.execute_reply": "2025-11-02T19:11:44.715783Z",
     "shell.execute_reply.started": "2025-11-02T19:11:44.575779Z"
    },
    "tags": []
   },
   "source": [
    "```c\n",
    "#include <pthread.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <unistd.h> // for sleep()\n",
    "\n",
    "// A simple function that will be run in a thread.\n",
    "// It takes a void* argument and returns a void*.\n",
    "// This is the required signature for a thread function.\n",
    "void* print_numbers(void* arg);\n",
    "void* print_letters(void* arg);\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    pthread_t thread1, thread2; // These are handles for our threads, like file descriptors.\n",
    "\n",
    "    printf(\"Main: Starting threads...\\n\");\n",
    "\n",
    "    // Create the first thread. It will run the print_numbers function.\n",
    "    if (pthread_create(&thread1, NULL, print_numbers, NULL) != 0) {\n",
    "        perror(\"Failed to create thread1\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Create the second thread. It will run the print_letters function.\n",
    "    if (pthread_create(&thread2, NULL, print_letters, NULL) != 0) {\n",
    "        perror(\"Failed to create thread2\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    printf(\"Main: Threads started. Waiting for them to finish...\\n\");\n",
    "\n",
    "    // pthread_join is crucial. It makes the main thread WAIT for the other threads to finish.\n",
    "    // If we didn't do this, main might exit immediately, killing the child threads.\n",
    "    // pthread_join(thread1, NULL);\n",
    "    // pthread_join(thread2, NULL);\n",
    "\n",
    "    printf(\"Main: Both threads have finished.\\n\");\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void* print_numbers(void* arg)\n",
    "{\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        printf(\"Number: %d\\n\", i);\n",
    "        sleep(1); // 1 sec\n",
    "    }\n",
    "    return NULL;\n",
    "}\n",
    "void* print_letters(void* arg)\n",
    "{\n",
    "    for (char c = 'a'; c <= 'e'; c++) {\n",
    "        printf(\"Letter: %c\\n\", c);\n",
    "        sleep(1);\n",
    "    }\n",
    "    return NULL;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd17702a-6389-4c98-aa74-3f786b080f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:18:56.850047Z",
     "iopub.status.busy": "2025-11-03T11:18:56.849547Z",
     "iopub.status.idle": "2025-11-03T11:18:57.241887Z",
     "shell.execute_reply": "2025-11-03T11:18:57.240107Z",
     "shell.execute_reply.started": "2025-11-03T11:18:56.849995Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Starting threads...\n",
      "Number: 0\n",
      "Letter: a\n",
      "Main: Threads started. Waiting for them to finish...\n",
      "Main: Both threads have finished.\n"
     ]
    }
   ],
   "source": [
    "!gcc -o src/concurrent_no_join src/concurrent_no_join.c -lpthread\n",
    "!src/concurrent_no_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "063ae3e2-a006-4a99-afc5-c6a0b18dfb66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:19:03.356369Z",
     "iopub.status.busy": "2025-11-03T11:19:03.355768Z",
     "iopub.status.idle": "2025-11-03T11:19:03.516160Z",
     "shell.execute_reply": "2025-11-03T11:19:03.499708Z",
     "shell.execute_reply.started": "2025-11-03T11:19:03.356318Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Starting threads...\n",
      "Main: Threads started. Waiting for them to finish...\n",
      "Number: 0\n",
      "Letter: a\n",
      "Main: Both threads have finished.\n"
     ]
    }
   ],
   "source": [
    "!src/concurrent_no_join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ad606-49e5-447f-88d6-5b0523bcd958",
   "metadata": {},
   "source": [
    "### A Production-Level Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab6010-63e9-4d5a-85c7-7db49d939289",
   "metadata": {},
   "source": [
    "We need to introduce more chaos. We'll remove the artificial synchronization of `sleep` and make the threads do *real, variable-length work* that the scheduler can't predict.\n",
    "\n",
    "Here is a modified version of the C program. Let's call it `concurrent_chaos.c`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49667fa-93f0-4d0e-bf96-f7673b8b59aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T19:50:12.806437Z",
     "iopub.status.busy": "2025-11-02T19:50:12.804920Z",
     "iopub.status.idle": "2025-11-02T19:50:13.043925Z",
     "shell.execute_reply": "2025-11-02T19:50:13.042937Z",
     "shell.execute_reply.started": "2025-11-02T19:50:12.806357Z"
    },
    "tags": []
   },
   "source": [
    "```c\n",
    "#include <pthread.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "\n",
    "// A function to simulate some \"work\" (a CPU-bound calculation)\n",
    "// The amount of work is variable to upset any rhythm.\n",
    "void do_work(int iterations);\n",
    "void* print_numbers(void* arg);\n",
    "void* print_letters(void* arg);\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    pthread_t thread1, thread2;\n",
    "\n",
    "    printf(\"Main: Starting threads...\\n\");\n",
    "\n",
    "    if (pthread_create(&thread1, NULL, print_numbers, (void*)1) != 0) {\n",
    "        perror(\"Failed to create thread1\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    if (pthread_create(&thread2, NULL, print_letters, (void*)2) != 0) {\n",
    "        perror(\"Failed to create thread2\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    printf(\"Main: Threads started. Waiting...\\n\");\n",
    "    pthread_join(thread1, NULL);\n",
    "    pthread_join(thread2, NULL);\n",
    "}\n",
    "\n",
    "void do_work(int iterations)\n",
    "{\n",
    "    volatile double x = 1.0; // 'volatile' prevents compiler from optimizing the loop away\n",
    "\n",
    "    for (int i = 0; i < iterations; i++)\n",
    "        x = x * 1.01;\n",
    "}\n",
    "\n",
    "void* print_numbers(void* arg)\n",
    "{\n",
    "    int work_base = 1000000;\n",
    "    srand(time(NULL) ^ ((long)arg + 1)); // Seed RNG uniquely for this thread\n",
    "\n",
    "    for (int i = 0; i < 5; i++) {\n",
    "        printf(\"Number: %d\\n\", i);\n",
    "        int iterations = work_base + (rand() % 1000000);\n",
    "        do_work(iterations);\n",
    "    }\n",
    "    return NULL;\n",
    "}\n",
    "\n",
    "void* print_letters(void* arg)\n",
    "{\n",
    "    // Let's use a variable amount of work for each step\n",
    "    int work_base = 1000000;\n",
    "    srand(time(NULL) ^ (long)arg); // Different seed for this thread\n",
    "\n",
    "    for (char c = 'a'; c <= 'e'; c++) {\n",
    "        printf(\"Letter: %c\\n\", c);\n",
    "        // Do a random amount of work between steps\n",
    "        int iterations = work_base + (rand() % 1000000);\n",
    "        do_work(iterations);\n",
    "    }\n",
    "    return NULL;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efd8a97d-0884-4b7a-9057-4ac586cf550c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:19:15.938861Z",
     "iopub.status.busy": "2025-11-03T11:19:15.938419Z",
     "iopub.status.idle": "2025-11-03T11:19:16.386479Z",
     "shell.execute_reply": "2025-11-03T11:19:16.384830Z",
     "shell.execute_reply.started": "2025-11-03T11:19:15.938809Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Starting threads...\n",
      "Main: Threads started. Waiting...\n",
      "Letter: a\n",
      "Number: 0\n",
      "Number: 1\n",
      "Letter: b\n",
      "Letter: c\n",
      "Number: 2\n",
      "Letter: d\n",
      "Number: 3\n",
      "Letter: e\n",
      "Number: 4\n",
      "Main: Both threads have finished.\n"
     ]
    }
   ],
   "source": [
    "!gcc -o src/concurrent_chaos src/concurrent_chaos.c -lpthread\n",
    "!src/concurrent_chaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e038b1-38d8-42a0-98af-dd253c97ffbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:19:23.287537Z",
     "iopub.status.busy": "2025-11-03T11:19:23.286967Z",
     "iopub.status.idle": "2025-11-03T11:19:23.526272Z",
     "shell.execute_reply": "2025-11-03T11:19:23.524880Z",
     "shell.execute_reply.started": "2025-11-03T11:19:23.287478Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Starting threads...\n",
      "Number: 0\n",
      "Main: Threads started. Waiting...\n",
      "Letter: a\n",
      "Letter: b\n",
      "Number: 1\n",
      "Letter: c\n",
      "Number: 2\n",
      "Letter: d\n",
      "Number: 3\n",
      "Number: 4\n",
      "Letter: e\n",
      "Main: Both threads have finished.\n"
     ]
    }
   ],
   "source": [
    "!src/concurrent_chaos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a379de8-a908-4b73-ab9b-ca97b0f3c974",
   "metadata": {},
   "source": [
    "**Key Changes:**\n",
    "*   **Removed `sleep`:** We replaced it with a CPU-bound calculation loop (`do_work`).\n",
    "*   **Introduced Randomness:** Each thread now does a variable, unpredictable amount of work between print statements. This destroys the \"turn-taking\" rhythm.\n",
    "*   **Unique Random Seeds:** We pass a unique \"argument\" to each thread and use it to seed the random number generator, ensuring they don't have the same random sequence.\n",
    "\n",
    "This is the true nature of concurrent scheduling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f904a-abcb-4898-9387-fda5fad3063b",
   "metadata": {},
   "source": [
    "## Python example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35586d28-daa0-4719-8028-366396f83260",
   "metadata": {},
   "source": [
    "Let's now bridge this directly to Python. The `threading` module provides an object-oriented interface to these exact same OS-level pthreads.\n",
    "\n",
    "Here is the Python equivalent of your first, more predictable C program.\n",
    "\n",
    "Run this Python code. You will see the same kind of interleaved output. The structure is a direct mapping:\n",
    "*   `pthread_create` -> `threading.Thread()` + `.start()`\n",
    "*   `pthread_join` -> `.join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21e7413c-19ba-4de0-9da3-6acd17a61d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:19:35.324198Z",
     "iopub.status.busy": "2025-11-03T11:19:35.323526Z",
     "iopub.status.idle": "2025-11-03T11:19:35.333409Z",
     "shell.execute_reply": "2025-11-03T11:19:35.331098Z",
     "shell.execute_reply.started": "2025-11-03T11:19:35.324137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def print_numbers(n):\n",
    "    \"\"\"Print numbers.\"\"\"\n",
    "    for i in range(n):\n",
    "        time.sleep(1)\n",
    "        print(f\"Number: {i}\")\n",
    "\n",
    "\n",
    "def print_letters(string):\n",
    "    \"\"\"Print letters.\"\"\"\n",
    "    for letter in string:\n",
    "        time.sleep(1)\n",
    "        print(f\"Letter: {letter}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d775b6-97fe-4698-a1f8-5630eff04474",
   "metadata": {},
   "source": [
    "### Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30a07fd0-3412-4809-804c-93c640cbc6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:20:08.710102Z",
     "iopub.status.busy": "2025-11-03T11:20:08.709563Z",
     "iopub.status.idle": "2025-11-03T11:20:18.724222Z",
     "shell.execute_reply": "2025-11-03T11:20:18.720600Z",
     "shell.execute_reply.started": "2025-11-03T11:20:08.710052Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 0\n",
      "Number: 1\n",
      "Number: 2\n",
      "Number: 3\n",
      "Number: 4\n",
      "Letter: a\n",
      "Letter: b\n",
      "Letter: c\n",
      "Letter: d\n",
      "Letter: e\n",
      "Time: 10.0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Run code.\"\"\"\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    print_numbers(5)\n",
    "    print_letters(\"abcde\")\n",
    "\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    print(f\"Time: {round(end - start, 2)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f75cd-fb94-4796-9e1a-f75f2cfed53c",
   "metadata": {},
   "source": [
    "### Concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3168708c-ddcc-41aa-a56c-b49a888151cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:20:37.665237Z",
     "iopub.status.busy": "2025-11-03T11:20:37.664664Z",
     "iopub.status.idle": "2025-11-03T11:20:42.685557Z",
     "shell.execute_reply": "2025-11-03T11:20:42.682012Z",
     "shell.execute_reply.started": "2025-11-03T11:20:37.665185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Starting threads...\n",
      "Main: Threads started. Waiting for them to finish...\n",
      "Number: 0Letter: a\n",
      "\n",
      "Letter: bNumber: 1\n",
      "\n",
      "Number: 2\n",
      "Letter: c\n",
      "Number: 3\n",
      "Letter: d\n",
      "Number: 4\n",
      "Letter: e\n",
      "Main: Both threads have finished.\n",
      "Time: 5.0\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run code.\"\"\"\n",
    "    print(\"Main: Starting threads...\")\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    t1 = threading.Thread(target=print_numbers, args=(5,))\n",
    "    t2 = threading.Thread(target=print_letters, args=(\"abcde\",))\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    print(\"Main: Threads started. Waiting for them to finish...\")\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    print(\"Main: Both threads have finished.\")\n",
    "    print(f\"Time: {round(end - start, 2)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99783c6c-9ece-4e01-887a-0efcc0bf1aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:20:57.117932Z",
     "iopub.status.busy": "2025-11-03T11:20:57.117353Z",
     "iopub.status.idle": "2025-11-03T11:21:02.312544Z",
     "shell.execute_reply": "2025-11-03T11:21:02.308041Z",
     "shell.execute_reply.started": "2025-11-03T11:20:57.117865Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main: Starting threads...\n",
      "Main: Threads started. Waiting for them to finish...\n",
      "Number: 0\n",
      "Letter: a\n",
      "Number: 1\n",
      "Letter: b\n",
      "Number: 2\n",
      "Letter: c\n",
      "Number: 3\n",
      "Letter: d\n",
      "Number: 4\n",
      "Letter: e\n",
      "Main: Both threads have finished.\n",
      "Time: 5.0\n"
     ]
    }
   ],
   "source": [
    "!python3.14 src/concurrent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406502a4-0ee5-4cf5-b489-5815cf312c32",
   "metadata": {},
   "source": [
    "Now, for the crucial production-level insight. In Python 3.14t with free-threading, these `print_letters` and `print_numbers` threads can run on *different CPU cores simultaneously*. The `print` function, however, involves a shared resource: the standard output (`stdout`). The Python interpreter internally uses a lock to make `stdout` thread-safe, so you don't get garbled output like \"LNumettbeer: r A: 0\". This is an example of the interpreter handling one class of thread-safety for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6581ff-f5a3-4978-936b-a785216f0f69",
   "metadata": {},
   "source": [
    "# <b>1.2 Hardware level Explanation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127e46c-3436-4a34-b795-3e0b7f3ad270",
   "metadata": {},
   "source": [
    "## What is a \"thread\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e335429-d4ab-47bd-a4fc-99e34ede7852",
   "metadata": {},
   "source": [
    "Let's step back and talk more about how the threads work on the hardware level. The definition \"smaller units of a process\" is too high level and leaves disappointment. That definition is a useless abstraction. Let's talk about the **metal**. Let's get our hands dirty with **registers**, **caches**, and **cores**.\n",
    "\n",
    "Forget software for a moment. Imagine a single CPU core. It has:\n",
    "\n",
    "* **Registers:** A tiny, ultrafast memory bank *inside* the CPU itself (e.g., **RIP** for the instruction pointer, RAX for a general-purpose value).\n",
    "* **The ALU:** The Arithmetic Logic Unit, the part that actually does the math.\n",
    "* **A Cache Hierarchy:** Small, fast memory (L1, L2) holding copies of recent data from main RAM.\n",
    "\n",
    "A **thread of execution**, at the hardware level, is the state of that core. It is the *current values of all its registers*, especially the **Instruction Pointer (RIP)** which tells it \"what line of code to run next.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b218a66-ea18-4951-a3be-028e12c40074",
   "metadata": {},
   "source": [
    "### Scenario 1: A Single Core, Two Threads (The Old Way)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b386e-d031-405d-abe3-7b0f79104a51",
   "metadata": {},
   "source": [
    "You have one CPU core and two software threads (like our two pthreads). The core can only be in one state at a time. It can't hold two different RIPs.\n",
    "\n",
    "So, the OS performs **Context Switching**:\n",
    "\n",
    "1.  The OS scheduler, a privileged piece of code, decides thread A has run long enough.\n",
    "2.  It triggers an interrupt. The core stops executing your thread A's code and jumps to the OS's scheduler code.\n",
    "3.  The OS *saves the entire execution state of thread A*: all register values, including RIP, are copied into a data structure in memory.\n",
    "4.  The OS *loads the saved state of thread B*: it copies thread B's saved registers back into the CPU's actual registers. This includes thread B's RIP.\n",
    "5.  The core resumes. But now, with thread B's state loaded, it's as if thread B was never interrupted. It continues from exactly where it left off.\n",
    "\n",
    "This is **concurrency** but not **parallelism**. The single core is rapidly switching its state, giving the illusion of simultaneous execution. The non-determinism comes from the timing of the scheduler's interrupts (which can be based on a timer or I/O events)â€”**this is why your thread-unsafe code sometimes works and sometimes breaks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2f6ba-8208-4509-bd19-c504f872f79c",
   "metadata": {},
   "source": [
    "### Scenario 2: Multiple Cores, Two Threads (The Modern Reality & Python 3.14t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc377288-90f2-4b56-8e24-db612ed1ce74",
   "metadata": {},
   "source": [
    "You have a multi-core CPU. Now, Core 1 and Core 2 are physically distinct pieces of silicon. Each has its own registers, its own ALU, its own L1 cache.\n",
    "\n",
    "* **Core 1** can load the state of Thread A ($RIP_A$, $registers_A$).\n",
    "* **Core 2** *simultaneously* loads the state of Thread B ($RIP_B$, $registers_B$).\n",
    "\n",
    "They now execute **in true parallel**. The electrical signals are literally flowing through two separate processor pipelines at the same time. This is the **\"free-threading\"** revolution in **Python 3.14t**: it allows Python threads to be scheduled onto separate cores to run in parallel, not just take turns on one core."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2041b6d-7a58-412d-a8b2-9e6799d0cd65",
   "metadata": {},
   "source": [
    "### The Crucial Hardware Consequence: Caches and Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99c46a-59c6-4364-a7c7-d5fef7f03d31",
   "metadata": {},
   "source": [
    "This is where the real problems, the \"production-level\" issues, arise.\n",
    "\n",
    "Each core has its own private L1/L2 cache. Main RAM is slow; caches are fast. When Core 1 reads a variable (e.g., a global counter), it gets a copy of that data into its local cache. If it increments the counter, it increments the *cached copy*.\n",
    "\n",
    "What happens if Core 2 reads the *same* counter at the same time? It gets the *old* value from main RAM into its own cache. Now both cores have different versions of the same data. They both increment their local copies. Then they eventually write back to main RAM. One core's update will be **lost**.\n",
    "\n",
    "**This is a Data Race.** It's not just a software bug; it's a direct consequence of the hardware memory architecture.\n",
    "\n",
    "The solution? The hardware provides instructions for **cache coherency** and **atomic operations**. A **Lock** in Python, built on a **mutex** (an OS primitive), ultimately relies on these low-level CPU instructions to ensure only one core can execute a read-modify-write sequence at a time.\n",
    "\n",
    "So, a Python thread is not an abstraction. It is a **software-managed handle for a hardware thread of execution**. When you create a Python thread, you are asking the OS to schedule a hardware state (registers, RIP) onto a physical CPU core. The chaos you observed in our C and Python experiments is the visible outcome of this hardware scheduling and cache behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3fd0ea-41d3-41c8-afea-fda56665a58d",
   "metadata": {},
   "source": [
    "## What is a \"process\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58398840-42dd-4f60-907d-606a3f543fa5",
   "metadata": {},
   "source": [
    "The process can consist of many threads, and this is the core of modern computing. Let's break down the hardware reality of a process.\n",
    "\n",
    "A **process** is an **allocation of resources**. A **thread** is a **stream of execution**.\n",
    "\n",
    "Think of it like a construction company:\n",
    "\n",
    "*   **The Process is the Company's Job Site.**\n",
    "    *   It has a defined **plot of land** (its Memory Address Space). This is the \"40-acre field\" where it's allowed to build. No other job site can build on this land.\n",
    "    *   It has **blueprints** (the executable code), stored on-site.\n",
    "    *   It has **heavy equipment** (like a crane) that is shared across the site (e.g., Open Files, Sockets).\n",
    "    *   This \"job site\" is a *resource container*.\n",
    "\n",
    "*   **Threads are the Construction Crews working on that site.**\n",
    "    *   Each crew (thread) has its own set of *hand tools* (Registers, Stack).\n",
    "    *   All crews share access to the entire site: they can all use the blueprints, operate the shared crane, and bring materials from anywhere on the 40-acre plot (the shared Heap and Global memory).\n",
    "    *   They are the ones *doing the work*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c48fa-8c97-4541-a373-4ab7f909a7ba",
   "metadata": {},
   "source": [
    "### The Hardware-Level View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ca698-6db6-496a-abf8-6d3cbaa3d1e7",
   "metadata": {},
   "source": [
    "Let's map this to your computer's hardware:\n",
    "\n",
    "| Component | Process (The Job Site) | Thread (A Crew) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Memory (RAM)** | Has its own **private Memory Address Space**. A memory address (e.g., `0x7f8a1c000000`) in Process A points to a different physical chip location than the same address in Process B. The Memory Management Unit (MMU) in the CPU handles this translation. | All threads **share the same Memory Address Space** of their parent process. A global variable at address `0x55a1a2b3c4d0` is the *same physical memory* for all threads in the process. |\n",
    "| **CPU Registers** | A process doesn't \"have\" registers directly. | **Each thread has its own COMPLETE, INDEPENDENT set of CPU registers** (RAX, RBX, RIP, RSP, etc.). This is its \"hardware state.\" When a thread is scheduled onto a core, its registers are loaded. |\n",
    "| **Stack** | The process has a main stack, but... | **Each thread gets its own, separate stack memory** (inside the process's address space). This is where local function variables, return addresses, and function parameters live. This is critical so that threads can call functions without trampling each other. |\n",
    "| **Heap & Globals** | The process owns one heap. | **All threads share the same heap and global variables.** This is why data races happen: two threads on two different cores can be manipulating the same data structure in the same heap memory at the same time. |\n",
    "| **OS Resources** | The process holds file descriptors, network sockets, etc. | Threads share these resources. One thread can open a file, and another thread in the same process can read from it. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3aab0-c460-4b09-aa86-b16618c68adb",
   "metadata": {},
   "source": [
    "### The Concrete Hardware Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f2ca4-bf5c-47ea-a94d-2e1201827741",
   "metadata": {},
   "source": [
    "Let's imagine Process P has two threads, T1 and T2.\n",
    "\n",
    "1.  **Process P is Created:** The OS allocates a range of physical RAM for its address space, loads the code from disk into that RAM, and sets up initial data structures.\n",
    "\n",
    "2.  **Thread T1 is Created:** The OS allocates a new, small memory region *within Process P's address space* for T1's **stack**. It then creates a data structure (a Thread Control Block) where it will save T1's **hardware state** (its registers).\n",
    "\n",
    "3.  **Thread T2 is Created:** The OS does the same: a new stack for T2 within P's memory, and a new Thread Control Block for T2's state.\n",
    "\n",
    "4.  **Scheduling:** The OS scheduler looks at T1 and T2 as independent, schedulable entities. It can choose to:\n",
    "    *   Put T1 on Core 1 and T2 on Core 2 (**True Parallelism**).\n",
    "    *   Time-slice T1 and T2 on a single core (**Concurrent Switching**).\n",
    "\n",
    "5.  **Execution on Core 1 (T1):**\n",
    "    *   The CPU's MMU is configured to point to Process P's memory map.\n",
    "    *   Core 1's registers are loaded from T1's saved state. The **Instruction Pointer (RIP)** now points to T1's next line of code. The **Stack Pointer (RSP)** points to T1's private stack.\n",
    "    *   Core 1 executes. It fetches instructions and data from P's memory using T1's RIP. It uses T1's stack for function calls.\n",
    "\n",
    "6.  **Execution on Core 2 (T2):**\n",
    "    *   The CPU's MMU on Core 2 is *also* configured to point to the *same* Process P memory map.\n",
    "    *   Core 2's registers are loaded from T2's saved state. It has a **different RIP** and a **different RSP**.\n",
    "    *   Core 2 executes completely independently, but it's reading and writing to the *same shared heap memory* as Core 1.\n",
    "\n",
    "This is the fundamental difference. **Processes are isolated memory domains. Threads are cooperative execution units within a single memory domain.**\n",
    "\n",
    "This is also why creating a process is \"heavy\" (you have to allocate a whole new address space) and a thread is \"light\" (you just need a new stack and a register set). And most importantly, it's why threads are so dangerous and powerful: they share everything by default, so communication is cheap, but you have no protection from each other's mistakes. A wild pointer in one thread can corrupt memory for all its sibling threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50733292-d487-40fb-b435-6df29470d46f",
   "metadata": {},
   "source": [
    "## How the final code is read and executed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a66663-8582-4d5a-99b8-046a9f827f68",
   "metadata": {},
   "source": [
    "We write:\n",
    "\n",
    "```python\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    print(\"Main: Threads started. Waiting for them to finish...\")\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "```\n",
    "\n",
    "So, how are these commands sent to the cores of CPU? One by one as we wrote them?\n",
    "\n",
    "Another fantastic question that cuts to the heart of the matter. You're thinking like a compiler and a CPU architect now.\n",
    "\n",
    "The answer is **no, they are not sent to the cores one-by-one as written.** The sequence you see in your code is a **logical sequence for the main thread**, not a physical command sequence to the CPU.\n",
    "\n",
    "Let's trace the hardware-level story of what happens. We'll follow the **Instruction Pointer (RIP)** of your main thread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db687611-f86b-4554-9ddf-556c53ae0b33",
   "metadata": {},
   "source": [
    "### The Main Thread's To-Do List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be6b5b-c6d8-4f6b-a375-90717c64ac5a",
   "metadata": {},
   "source": [
    "**File: `concurrent_example.py`**\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# ... function definitions ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Main: Starting threads...\")  # <-- RIP is here (1)\n",
    "```\n",
    "\n",
    "1.  Your main thread is running on, let's say, **Core 1**. Its RIP is moving through your `main` code.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "    thread1 = threading.Thread(target=print_letters) # <-- RIP is here (2)\n",
    "    thread2 = threading.Thread(target=print_numbers) # <-- RIP is here (3)\n",
    "```\n",
    "\n",
    "2.  & 3. These are just object constructions in memory. No OS thread exists yet. This is all happening sequentially in the main thread on **Core 1**.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "    thread1.start()  # <-- RIP is here (4). THIS IS THE CRITICAL MOMENT.\n",
    "```\n",
    "\n",
    "4.  `thread1.start()` is a function call that culminates in a **system call** (like `pthread_create`).\n",
    "      * The main thread's RIP is executing this on **Core 1**.\n",
    "      * The system call causes the CPU to temporarily switch from **User Mode** to **Kernel Mode** to process the request.\n",
    "      * The OS receives the request, allocates a new stack for T1, and creates a Thread Control Block.\n",
    "      * The OS scheduler now has a new, schedulable entity: **T1**. It might immediately schedule T1 onto an idle core (e.g., **Core 2**), or mark it as ready-to-run.\n",
    "      * **The `start()` function returns immediately.** The main thread's RIP on **Core 1** moves to the next line. It does **NOT** wait for T1 to actually start executing.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "    thread2.start()  # <-- RIP is here (5)\n",
    "```\n",
    "\n",
    "5.  The exact same, immediate sequence happens for T2. T2 is now available for scheduling, perhaps on **Core 3**. The `start()` call returns immediately.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "    print(\"Main: Threads started. Waiting for them to finish...\") # <-- RIP is here (6)\n",
    "```\n",
    "\n",
    "6.  The main thread on **Core 1** executes this `print`. Meanwhile, T1 on Core 2 and T2 on Core 3 are now running **concurrently and in parallel**. The main thread's output might appear *before, after, or interleaved with* the output from T1 and T2. This is the source of **non-determinism**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f1dcb-58ce-480d-a13d-896f5d113567",
   "metadata": {},
   "source": [
    "### Synchronization: The Blocking Barrier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e2968-d99f-4fff-a3eb-5428c43a67ae",
   "metadata": {},
   "source": [
    "```python\n",
    "    t1.join()  # <-- RIP is here (7). ANOTHER CRITICAL MOMENT.\n",
    "```\n",
    "\n",
    "7.  `t1.join()` is another function call, but this is a **blocking system call**.\n",
    "      * The main thread, on **Core 1**, tells the OS: \"My instruction pointer must not proceed past this point until thread T1 has terminated.\"\n",
    "      * The OS enters Kernel Mode, finds the main thread, and changes its state from *Running* to *Waiting*.\n",
    "      * The OS de-schedules the main thread, typically placing it on a **wait queue** associated with the Thread Control Block of T1.\n",
    "      * **Core 1 is now free** and is immediately offered to the scheduler to run another ready thread.\n",
    "      * The main thread's RIP is **frozen**.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "    t2.join()  # <-- Once T1 dies, the OS wakes up the main thread and its RIP moves here (8).\n",
    "```\n",
    "\n",
    "8.  When T1 finishes, the OS removes the main thread from the wait queue and places it back on the **ready queue**. The main thread is eventually scheduled back onto a core (not necessarily Core 1) and its RIP proceeds to `t2.join()`. The same blocking sequence happens until T2 terminates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5401c-6675-4281-9d91-4a99c282ab9e",
   "metadata": {},
   "source": [
    "### The Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85074257-b4f4-4477-80eb-46b8a69f48be",
   "metadata": {},
   "source": [
    "  * `start()` is a **fire-and-forget command**. It immediately returns control and creates an independent execution stream.\n",
    "  * `join()` is a **synchronization barrier**. It forces the executing thread to stop and wait for another thread's state change (its death), freeing up the CPU core for productive work in the meantime.\n",
    "  * **Your single stream of instructions (the main thread) is orchestrating the creation of other, independent streams.** The lines of code are executed sequentially *by the main thread*, but their *effect* is to create chaos and parallelism.\n",
    "\n",
    "The sequence in the file is the main thread's to-do list, not a script being broadcast to the cores. The cores are all independently chewing through the instructions of their assigned threads, which is why we need primitives like `join()` to impose order on the chaos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3a079-2513-455e-b10e-08308e39fea8",
   "metadata": {},
   "source": [
    "# <b>1.3 Python's `threading.Thread` API</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb5a72-d9de-45e0-9bce-a8e019816b45",
   "metadata": {},
   "source": [
    "Now that we have a robust mental model of threads at the hardware level, the Python API will make much more sense. It's not just syntax; it's an interface for managing those independent streams of execution we just discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ecbe5a-0117-47b3-919e-71d2301ece1b",
   "metadata": {},
   "source": [
    "## Thread Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954a397-664d-48d5-bed4-344aa3aa29ca",
   "metadata": {},
   "source": [
    "Let's break down the **Thread Lifecycle** using the API. A thread can be in one of several states, and the `threading` module gives you the tools to manage the transitions.\n",
    "\n",
    "Here is a conceptual diagram of the lifecycle:\n",
    "\n",
    "```mermaid\n",
    "---\n",
    "config:\n",
    "  look: handDrawn\n",
    "  theme: redux\n",
    "  layout: elk\n",
    "---\n",
    "flowchart TD\n",
    " subgraph subGraph0[\"OS-Managed Thread State Diagram\"]\n",
    "        A[\"New Thread<br>t = Thread(...)\"]\n",
    "        B[\"Runnable (Ready Queue)\"]\n",
    "        C[\"Running (on Core)\"]\n",
    "        D[\"Terminated (Zombie)\"]\n",
    "        E[\"Waiting / Blocked\"]\n",
    "        F[\"Main Thread Blocked (on Wait Queue)\"]\n",
    "        G[\"Resources Collected / Cleanup\"]\n",
    "  end\n",
    "    A -- \"t.start()\" --> B\n",
    "    B -- OS Scheduler Dispatch --> C\n",
    "    C -- Target Thread Completes Task --> D\n",
    "    C -- \"Voluntary Yield<br>I/O Operation / time.sleep()\" --> E\n",
    "    E -- I/O Complete / Timer Expired --> B\n",
    "    C -- \"Main Thread calls t.join()\" --> F\n",
    "    D -- Target Thread Death<br>(OS Wakes Waiters) --> F\n",
    "    F -- Join Returns (Main Thread proceeds) --> G\n",
    "     A:::state\n",
    "     B:::state\n",
    "     C:::state\n",
    "     D:::state\n",
    "     E:::state\n",
    "     F:::state\n",
    "     G:::state\n",
    "    classDef state fill:#d3e9d3,stroke:#38761D\n",
    "    linkStyle 0 stroke:#1F77B4,stroke-width:3px,fill:none\n",
    "    linkStyle 1 stroke:#1F77B4,stroke-width:3px,fill:none\n",
    "    linkStyle 2 stroke:#2CA02C,stroke-width:3px,fill:none\n",
    "    linkStyle 3 stroke:#FF7F0E,stroke-width:3px,fill:none\n",
    "    linkStyle 4 stroke:#2CA02C,stroke-width:3px,fill:none\n",
    "    linkStyle 5 stroke:#1F77B4,stroke-width:3px,fill:none\n",
    "    linkStyle 6 stroke:#2CA02C,stroke-width:3px,fill:none\n",
    "    linkStyle 7 stroke:#9467BD,stroke-width:3px,fill:none\n",
    "```\n",
    "\n",
    "> Fig. 1 \"OS-Managed Thread State Transitions\"\n",
    "\n",
    "And here is how the Python `threading` API maps to this lifecycle:\n",
    "\n",
    "| Lifecycle State | Python `threading` API Trigger |\n",
    "| :--- | :--- |\n",
    "| **New** | `thread = threading.Thread(target=my_function)` |\n",
    "| **Runnable** | `thread.start()` |\n",
    "| **Running** | (Controlled by the OS Scheduler) |\n",
    "| **Waiting/Blocked** | `time.sleep()`, `lock.acquire()` (on a held lock), I/O operations. |\n",
    "| **Terminated** | `target` function returns or raises an exception. |\n",
    "| **Main Thread Synchronization** | `thread.join()` - Main thread waits for this thread to terminate. |\n",
    "\n",
    "Two critical, production-relevant details:\n",
    "\n",
    "1.  **The \"Zombie\" State (Terminated):** When a thread's `target` function returns, the thread enters a \"Terminated\" or \"Zombie\" state. It is no longer schedulable and its execution has ceased, but its resources (like its thread control block and return value) are still held by the OS/Interpreter until someone acknowledges its death. This is a crucial detail for resource management.\n",
    "\n",
    "2.  **The \"Wait Queue\":** The `t.join()` call does not simply make the main thread \"sleep.\" It places the main thread on a specific **wait queue** for that terminating thread. When the target thread finally dies, the OS/Interpreter explicitly wakes up *all threads* that are waiting in that queue. This is a much more accurate description of the synchronization mechanism.\n",
    "\n",
    "It explains *why* `join` works and what's happening under the hood. In a complex, long-running server application, understanding that threads pass through a \"Zombie\" state before cleanup can be important for diagnosing resource leaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934424f-acb2-4dc2-8328-350c787011ca",
   "metadata": {},
   "source": [
    "# My turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0852ef-0c83-4d7d-80d4-e3150305af69",
   "metadata": {},
   "source": [
    "Your mission is to write a Python program that brings this lifecycle diagram to life. Use the `threading.Thread` API to create, start, and monitor a `worker` thread from your `main` thread.\n",
    "\n",
    "Here is the specific task again, for clarity:\n",
    "\n",
    "1.  Create a worker thread that runs a function which loops 5 times.\n",
    "2.  In each iteration, the function should print its state (e.g., \"Worker: Loop 1\") and then sleep for a short, fixed period (e.g., 0.5 seconds).\n",
    "3.  In your main thread, *after starting the worker thread*, use a separate loop that also runs 5 times.\n",
    "4.  In each iteration of the *main* thread's loop, print \"Main: Check X\" and then use `thread.is_alive()` to check on the worker thread's status, printing the result.\n",
    "\n",
    "This will demonstrate the `New -> Runnable -> Running -> Waiting -> Terminated` lifecycle and show you how the main thread can supervise another thread's state.\n",
    "\n",
    "Let's be precise. You should create **only one new thread** within the main function.\n",
    "\n",
    "So, you will have a total of **two threads**:\n",
    "1.  The **Main Thread**: This is the one that starts when you run `python your_script.py`. It is automatically created by the Python interpreter and runs the code inside `if __name__ == \"__main__\":`.\n",
    "2.  The **Worker Thread**: This is the one you will explicitly create with `threading.Thread(...)` and `thread.start()`.\n",
    "\n",
    "The orchestration works as follows:\n",
    "\n",
    "*   The **Main Thread** will:\n",
    "    1.  Create and start the Worker Thread.\n",
    "    2.  Then, it will execute its own 5-iteration loop, where it prints and checks on the Worker Thread.\n",
    "\n",
    "*   The **Worker Thread** will:\n",
    "    1.  Independently execute its own 5-iteration loop, where it prints and sleeps.\n",
    "\n",
    "This setup will clearly show the two threads running their separate loops concurrently, and it allows the Main Thread to act as a supervisor for the Worker Thread.\n",
    "\n",
    "So, to be perfectly clear: you are writing code for **two threads total**. You are only explicitly creating **one new thread**. The main thread is your starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9000f-eb5e-4292-96c4-27344d4b3f55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d8ed716-7476-4ae5-be0e-f70de4343e9b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b985644a-ed08-4443-b992-c3b78bd7ad99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e49ae5fc-a46f-44f9-a8ab-377360545c18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07adc3-bcb6-41a2-b82b-9f29c6d3436b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f54fb169-42ee-41e6-9d0a-7704d3f7e087",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dfdaa6f-8c96-4c72-9b8e-50da9d94aa2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3e7997f-4bcf-41e5-9161-0379015d294f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv314t",
   "language": "python",
   "name": "venv314t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
